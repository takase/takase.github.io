###### ([slideshare](https://www.slideshare.net/shotakase33), [github](https://github.com/takase))

Assistant Professor at Okazaki lab, Tokyo Institute of Technology
e-mail: sho.takase [aatt] nlp.c.titech.ac.jp

## Research Interest
Knowledge acquisition  
Phrase/Sentence composition  
Neural Language Model

## Publications
#### Journal Papers
* Tatsuya Hiraoka, <u>Sho Takase</u>, Kei Uchiumi, Atsushi Keyaki, Naoaki Okazaki. Joint Optimization of Word Segmentation and Downstream Model using Downstream Loss. Journal of Natural Language Processing, vol. 29, No. 1, pp. 112--143, March 2022. [pdf](https://www.jstage.jst.go.jp/article/jnlp/29/1/29_112/_article/-char/ja)
* Tatsuya Hiraoka, <u>Sho Takase</u>, Kei Uchiumi, Atsushi Keyaki, Naoaki Okazaki. Recurrent Neural Hidden Markov Model for High-Order Transition. ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP), vol. 21, issue 2, pp. 1–-15, March 2022. [pdf](https://dl.acm.org/doi/pdf/10.1145/3476511)
* Tatsuya Hiraoka, <u>Sho Takase</u>, Kei Uchiumi, Atsushi Keyaki, Naoaki Okazaki. Optimizing Word Segmentation for Downstream Tasks by Weighting Text Vector (in Japanese). Journal of Natural Language Processing, vol. 28, No. 2, pp. 479--507, June 2021. [pdf](https://www.jstage.jst.go.jp/article/jnlp/28/2/28_479/_pdf/-char/ja)
* <u>Sho Takase</u>, Naoaki Okazaki, Kentaro Inui. Learning to Compose Distributed Representations of Relational Patterns (in Japanese). Transactions of the Japanese Society for Artificial Intelligence, vol. 32, No. 4., July 2017. [pdf](https://www.jstage.jst.go.jp/article/tjsai/32/4/32_D-G96/_pdf)
* <u>Sho Takase</u>, Naoaki Okazaki, Kentaro Inui. Modeling semantic compositionality of relational patterns. Engineering Applications of Artificial Intelligence, vol. 50, pp.256--264, April 2016. [pdf](http://ac.els-cdn.com/S0952197616000312/1-s2.0-S0952197616000312-main.pdf?_tid=ae7b0c08-dac8-11e5-93d8-00000aab0f01&acdnat=1456299296_77b433935f238167c491daab4fcf31f9)
* <u>Sho Takase</u>, Naoaki Okazaki, Kentaro Inui. Set Expansion Using Sibling Relationships Between Semantic Categories (in Japanese). Journal of Natural Language Processing, vol. 20, No. 2, June 2013. [pdf](https://www.jstage.jst.go.jp/article/jnlp/20/2/20_273/_pdf)


#### (Refereed) International Conference and Workshop Papers
* Mengsay Loem, <u>Sho Takase</u>, Masahiro Kaneko, Naoaki Okazaki. ExtraPhrase: Efficient Data Augmentation for Abstractive Summarization. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Student Research Workshop. pp. 16–-24, 2022. [pdf](https://aclanthology.org/2022.naacl-srw.3/)
* <u>Sho Takase</u>, Naoaki Okazaki. Multi-Task Learning for Cross-Lingual Abstractive Summarization. In Proceedings of the Thirteenth Language Resources and Evaluation Conference (LREC). pp. 3008--3016, 2022. [pdf](https://aclanthology.org/2022.lrec-1.322)
* Tatsuya Hiraoka, <u>Sho Takase</u>, Kei Uchiumi, Atsushi Keyaki, Naoaki Okazaki. Word-level Perturbation Considering Word Length and Compositional Subwords. pp. 3268-–3275, 2022. [pdf](https://aclanthology.org/2022.findings-acl.199/)
* <u>Sho Takase</u>, Tatsuya Hiraoka, Naoaki Okazaki. Single Model Ensemble for Subword Regularized Models in Low-Resource Machine Translation. In Findings of the Association for Computational Linguistics: ACL 2022. pp. 2536--2541, 2022. [pdf](https://aclanthology.org/2022.findings-acl.199/)
* Masahiro Kaneko, <u>Sho Takase</u>, Ayana Niwa, Naoaki Okazaki. Interpretability for Language Learners Using Example-Based Grammatical Error Correction. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. pp. 7176–-7187, 2022. [pdf](https://aclanthology.org/2022.acl-long.496/)
* Tatsuya Hiraoka, <u>Sho Takase</u>, Kei Uchiumi, Atsushi Keyaki, Naoaki Okazaki. Joint Optimization of Tokenization and Downstream Model. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 244--255, 2021. [pdf](https://aclanthology.org/2021.findings-acl.21/)
* <u>Sho Takase</u>, Shun Kiyono. Rethinking Perturbations in Encoder-Decoders for Fast Training. In Proceedings of 2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2021), pp. 5767–-5780, 2021. [pdf](https://aclanthology.org/2021.naacl-main.460.pdf), [code](https://github.com/takase/rethink_perturbations), [slide](https://www.slideshare.net/shotakase33/rethinking-perturbations-in-encoderdecoders-for-fast-training).
* <u>Sho Takase</u>, Sosuke Kobayashi. All Word Embeddings from One Embedding. In Proceedings of the thirty-fourth Conference on Neural Information Processing Systems (NeurIPS), 2020. [pdf](https://papers.nips.cc/paper/2020/hash/275d7fb2fd45098ad5c3ece2ed4a2824-Abstract.html), [code](https://github.com/takase/alone_seq2seq).
* Tatsuya Hiraoka, <u>Sho Takase</u>, Kei Uchiumi, Atsushi Keyaki, Naoaki Okazaki. Optimizing Word Segmentation for Downstream Task. In Findings of the Association for Computational Linguistics: EMNLP 2020. pp. 1341--1351, 2020.
* Kazuki Matsumaru, <u>Sho Takase</u>, Naoaki Okazaki. Improving Truthfulness of Headline Generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL 2020).
* Sho Shimazu, <u>Sho Takase</u>, Toshiaki Nakazawa, Naoaki Okazaki. Evaluation Dataset for Zero Pronoun in Japanese to English Translation. In Proceedings of The 12th Language Resources and Evaluation Conference (LREC 2020), pp. 3630--3634, 2020.
* Masaaki Nishino, <u>Sho Takase</u>, Tsutomu Hirao, Masaaki Nagata. Generating Natural Anagrams:Towards Language Generation Under Hard Combinatorial Constraints. In Proceedings of 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP 2019).
* Yuichi Sasazawa, <u>Sho Takase</u>, Naoaki Okazaki. Neural Question Generation using Interrogative Phrases. In Proceedings of the 12th International Conference on Natural Language Generation (INLG 2019), pp. 106--111, 2019.
* <u>Sho Takase</u>, Naoaki Okazaki. Positional Encoding to Control Output Sequence Length. In Proceedings of 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2019), pp. 3999--4004, 2019. [pdf](https://arxiv.org/abs/1904.07418), [code](https://github.com/takase/control-length).
* <u>Sho Takase</u>, Jun Suzuki, Masaaki Nagata. Character n-gram Embeddings to Improve RNN Language Models. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI 2019), pp. 5074--5082. 2019. [pdf](https://arxiv.org/abs/1906.05506).
* Shun Kiyono, <u>Sho Takase</u>, Jun Suzuki, Naoaki Okazaki, Kentaro Inui and Masaaki Nagata. Reducing Odd Generation from Neural Headline Generation. In the Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computing (PACLIC 32), 2018.
* Shun Kiyono, <u>Sho Takase</u>, Jun Suzuki, Naoaki Okazaki, Kentaro Inui and Masaaki Nagata. Unsupervised Token-wise Alignment to Improve Interpretation of Encoder-Decoder models. In the Proceedings of the Analyzing and interpreting neural networks for NLP (BlackboxNLP), 2018.
* <u>Sho Takase</u>, Jun Suzuki, Masaaki Nagata. Direct Output Connection for a High-Rank Language Model. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP 2018), pp. 4599--4609, 2018. [pdf](https://arxiv.org/abs/1808.10143), [code](https://github.com/nttcslab-nlp/doc_lm), [score](https://takase.github.io/lm_performance).
* Jun Suzuki, <u>Sho Takase</u>, Hidetaka Kamigaito, Makoto Morishita, Masaaki Nagata. An Empirical Study of Building a Strong Baseline for Constituency Parsing. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL 2018), pp.612--618, 2018.
* <u>Sho Takase</u>, Jun Suzuki, Masaaki Nagata. Input-to-Output Gate to Improve RNN Language Models. In Proceedings of the 8th International Joint Conference on Natural Language Processing (IJCNLP 2017), pp.43--48, November 2017. [pdf](http://aclweb.org/anthology/I/I17/I17-2008.pdf), [code](https://github.com/nttcslab-nlp/iog), [score](https://takase.github.io/lm_performance).
* Shota Sasaki, <u>Sho Takase</u>, Naoya Inoue, Naoaki Okazaki and Kentaro Inui. Handling Multiword Expressions in Causality Estimation. In proceedings of the 12th International Conference on Computational Semantics (IWCS 2017), Septembre 2017.
* <u>Sho Takase</u>, Jun Suzuki, Naoaki Okazaki, Tsutomu Hirao and Masaaki Nagata. Neural Headline Generation on Abstractive Meaning Representation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2016), pp. 1054--1059, November 2016. [pdf](https://aclweb.org/anthology/D16-1112)
* <u>Sho Takase</u>, Naoaki Okazaki and Kentaro Inui. Composing Distributed Representations of Relational Patterns. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016), pp.2276--2286, August 2016. [pdf](http://aclweb.org/anthology/P/P16/P16-1215.pdf), [poster](./ACL2016PosterPrint.pdf), [dataset](https://github.com/takase/relPatSim), [code](https://github.com/takase/GAC4relpat)
* <u>Sho Takase</u>, Naoaki Okazaki and Kentaro Inui. Fast and Large-scale Unsupervised Relation Extraction. In Proceedings of the 29th Pacific Asia Conference on Language Information and Computing (PACLIC29), pp.96--105, October 2015. [pdf](http://www.aclweb.org/anthology/Y15-1012)
* <u>Sho Takase</u>, Akiko Murakami, Miki Enoki, Naoaki Okazaki and Kentaro Inui. Detecting Chronic Critics Based on Sentiment Polarity and User’s Behavio in Social Media. In Proceedings of the ACL student research workshop 2013, pp.110--116, 2013. [pdf](http://www.aclweb.org/anthology/P13-3016)
* <u>Sho Takase</u>, Naoaki Okazaki and Kentaro Inui. Set Expansion using Sibling Relations between Semantic Categories. In Proceedings of the 26th Pacific Asia Conference on Language Information and Computing (PACLIC26), pp.525--534, November 2012. [pdf](http://www.aclweb.org/anthology/Y12-1057)


#### Preprint
* <u>Sho Takase</u>, Shun Kiyono, Sosuke Kobayashi, Jun Suzuki. On Layer Normalizations and Residual Connections in Transformers. [pdf](https://arxiv.org/abs/2206.00330), [code](https://github.com/takase/b2t_connection).

#### Misc
* <u>高瀬 翔</u>. NLP若手の会 (YANS) 第 16 回シンポジウム ―オンライン開催における施策について―. Journal of Natural Language Processing, vol. 28, No. 4, Dec 2021.
* <u>高瀬 翔</u>. 実験を通して既存手法を整理する ―系列変換タスクにおける摂動の効率の調査―. Journal of Natural Language Processing, vol. 28, No. 3, Sep 2021.
* <u>高瀬 翔</u>. NLP若手の会（YANS）シンポジウム. Journal of Natural Language Processing, vol. 28, No. 1, Mar 2021.
* <u>Sho Takase</u>, Naoaki Okazaki. Construction of Relation Knowledge Base from Natural Language Text. Journal of Japan Society for Fuzzy Theory and Intelligent Informatics, vol. 29, No. 2, pp.55--64, April 2017, in Japanese.


## Talks
* 少量の計算資源でも利用可能な自然言語処理モデルを目指して. 第27回ステアラボ人工知能セミナー, May, 2021. [pdf](https://www.slideshare.net/shotakase33/stair-lab-seminar-202105), [video](https://youtu.be/h7wTXHjYNxA).
* [NeurIPS2020の概観とニューラルモデルのパラメータ数削減](https://www.slideshare.net/shotakase33/neurips2020). 第79回人工知能セミナー, Mar, 2021.
* 自然言語処理におけるニューラルモデルのパラメータ数削減. 第5回愛媛大学DSセミナー, Feb 2021.
* [ニューラル言語モデルの研究動向](https://speakerdeck.com/takase/niyuraruyan-yu-moderufalse-yan-jiu-dong-xiang-nlyan-zhao-dai-jiang-yan-zi-liao). IPSJ-SIGNL 240, June 2019.
* [国際会議 EMNLP 2016 参加報告 (2)](http://www.ieice.org/ken/paper/20161221Nbo0/). 第18回音声言語シンポジウム & 第3回自然言語処理シンポジウム, December 2016.
* ACL 2013 参加報告. NLP若手の会第8回シンポジウム, September 2013.

<!-- 
* [Recent Studies on Neural Language Models（ニューラル言語モデルの研究動向）](https://speakerdeck.com/takase/niyuraruyan-yu-moderufalse-yan-jiu-dong-xiang-nlyan-zhao-dai-jiang-yan-zi-liao). IPSJ-SIGNL 240, June 2019.
* [International Conference Report EMNLP 2016 (2)](http://www.ieice.org/ken/paper/20161221Nbo0/). The 18th Spoken Language Symposium & The Third Natural Language Processing Symposium, December 2016.
* ACL 2013 Participation Report. The 8th NLP Symposium for Young Researchers, September 2013.
-->


## Awards
* The Association for Natural Language Processing Best paper award (first place) (2022).
* The 28th Annual Meeting of The Association for Natural Language Processing Special Committee Award (2022).
* The 28th Annual Meeting of the Association for Natural Language Processing Best Paper Award (2022).
* Outstanding reviewer, EMNLP-IJCNLP 2019 (2019).
* Information Processing Society of Japan, Special Interest Group of Natural Language Processing (IPSJ-SIGNL) [Excellent Research Award](https://nl-ipsj.or.jp/award/) (2019).
* The 25th Annual Meeting of the Association for Natural Language Processing Poster Award (2019)
* JSAI Best Paper Award (2018).
* The 24th Annual Meeting of the Association for Natural Language Processing Best Paper Award (2018).
* Dean's Award for Excellence in Graduate School of Information Sciences at Tohoku University (2017).
* The 29th Annual Meeting of the JSAI Conference Student Incentive Award (2015).
* The 21th Annual Meeting of the Association for Natural Language Processing Excellent Paper Award (2015).


<!-- 
## Grants
* JSPS Research Fellowships for Young Scientists (DC1)
* 科研費若手
* MSRA奨学寄附金
-->


## Program commitee member
* 言語処理学会会誌「自然言語処理」編集委員 (2020 - ).
* NLP若手の会（YANS）運営委員長 (2020 - 2022).
* Local committee and Workshop Chair of the 12th International Conference on Natural Language Generation (2019).
* NLP若手の会（YANS）運営委員 (2017 - 2018).

<!-- 
General Chair of Young Researcher Association for NLP Studies
Young Researcher Association for NLP Studies (YANS) 
-->

## Lecture
* 手続き型プログラミング（発展） (2020 - ).
* 知能情報フォーラム (2020 - ).
* 高次ヒューマンインタフェース（非常勤講師） (2020 - 2021).

## Biography
* Assistant Professor, Tokyo Institute of Technology (2020. 4 - ).
* Researcher, Tokyo Institute of Technology (2018.10 - 2020. 3).
* Research associate, NTT Communication Science Laboratories (2017.4 - 2018.9).
* Ph.D. Graduate School of Information Sciences, Tohoku University (2014. 4 - 2017. 3).
* M.Sc. Graduate School of Information Sciences, Tohoku University (2012. 4 - 2014. 3).
* B.Eng. Tohoku University (2008. 4 - 2012. 3).


